{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-07T00:36:14.876595Z","iopub.execute_input":"2021-12-07T00:36:14.877606Z","iopub.status.idle":"2021-12-07T00:36:14.904950Z","shell.execute_reply.started":"2021-12-07T00:36:14.877035Z","shell.execute_reply":"2021-12-07T00:36:14.904294Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/state-farm-distracted-driver-detection/driver_imgs_list.csv')\ndf.head(5)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-07T00:36:14.907789Z","iopub.execute_input":"2021-12-07T00:36:14.909300Z","iopub.status.idle":"2021-12-07T00:36:14.958853Z","shell.execute_reply.started":"2021-12-07T00:36:14.909261Z","shell.execute_reply":"2021-12-07T00:36:14.958108Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"len(df)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T00:36:14.960021Z","iopub.execute_input":"2021-12-07T00:36:14.960408Z","iopub.status.idle":"2021-12-07T00:36:14.966952Z","shell.execute_reply.started":"2021-12-07T00:36:14.960370Z","shell.execute_reply":"2021-12-07T00:36:14.966205Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"#SPLIT INTO TRAIN AND TEST","metadata":{}},{"cell_type":"code","source":"#https://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas\ndf = df.sample(frac = 1)\ntt = np.random.rand(len(df)) < 0.8\ntrain_data = df[tt]\ntest_data = df[~tt]\nprint(\"Train dataset lenght\",len(train_data))\nprint(\"Test dataset lenght\",len(test_data))","metadata":{"execution":{"iopub.status.busy":"2021-12-07T00:36:14.969525Z","iopub.execute_input":"2021-12-07T00:36:14.969986Z","iopub.status.idle":"2021-12-07T00:36:14.986477Z","shell.execute_reply.started":"2021-12-07T00:36:14.969946Z","shell.execute_reply":"2021-12-07T00:36:14.984632Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"The 10 classes to predict are:\n\nc0: normal driving\nc1: texting - right\nc2: talking on the phone - right\nc3: texting - left\nc4: talking on the phone - left\nc5: operating the radio\nc6: drinking\nc7: reaching behind\nc8: hair and makeup\nc9: talking to passenger","metadata":{}},{"cell_type":"code","source":"types = {'c0': 'normal driving', \n        'c1': 'texting - right', \n        'c2': 'talking on the phone - right', \n        'c3': 'texting - left', \n        'c4': 'talking on the phone - left', \n        'c5': 'operating the radio', \n        'c6': 'drinking', \n        'c7': 'reaching behind', \n        'c8': 'hair and makeup', \n        'c9': 'talking to passenger'}\nnumber_of_class = 10 ","metadata":{"execution":{"iopub.status.busy":"2021-12-07T00:36:14.987885Z","iopub.execute_input":"2021-12-07T00:36:14.988642Z","iopub.status.idle":"2021-12-07T00:36:14.994084Z","shell.execute_reply.started":"2021-12-07T00:36:14.988605Z","shell.execute_reply":"2021-12-07T00:36:14.993048Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"LOADING IMAGE IN GRAYSCALE","metadata":{}},{"cell_type":"code","source":"#https://towardsdatascience.com/convolution-neural-network-for-image-processing-using-keras-dc3429056306\n\nimport cv2\n\ndef grayscale(path):\n    img = cv2.imread(path, 0)\n    img = cv2.resize(img, (64, 64))#reduce the size of the image\n    return img ","metadata":{"execution":{"iopub.status.busy":"2021-12-07T00:36:14.995561Z","iopub.execute_input":"2021-12-07T00:36:14.996188Z","iopub.status.idle":"2021-12-07T00:36:15.189604Z","shell.execute_reply.started":"2021-12-07T00:36:14.996123Z","shell.execute_reply":"2021-12-07T00:36:15.188772Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"GET train images and their label from the files","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nfrom glob import glob\n\ndef loadtrain():\n    train_images = [] \n    train_labels = []\n    for classed in tqdm(range(number_of_class)):\n        print('Loading directory c{}'.format(classed))\n        files = glob(os.path.join('../input/state-farm-distracted-driver-detection/imgs/train/c' + str(classed), '*.jpg'))\n        for file in files:\n            img = grayscale(file)\n            train_images.append(img)\n            train_labels.append(classed)\n    return train_images, train_labels ","metadata":{"execution":{"iopub.status.busy":"2021-12-07T00:36:15.190773Z","iopub.execute_input":"2021-12-07T00:36:15.191077Z","iopub.status.idle":"2021-12-07T00:36:15.197292Z","shell.execute_reply.started":"2021-12-07T00:36:15.191038Z","shell.execute_reply":"2021-12-07T00:36:15.196322Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"MAKING VALIDATION DATASET FROM TRAIN DATASET","metadata":{}},{"cell_type":"code","source":"##https://www.kaggle.com/pierrelouisdanieau/computer-vision-tips-to-increase-accuracy\n\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import np_utils\n\ndef normalize_train_data():\n    X, labels = loadtrain()\n    y = np_utils.to_categorical(labels, 10)\n    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    x_train = np.array(x_train, dtype=np.uint8).reshape(-1,64,64,1)\n    x_test = np.array(x_test, dtype=np.uint8).reshape(-1,64,64,1)\n\n    return x_train, x_test, y_train, y_test\n\ndef loadvalid(size=200000):\n    path = os.path.join('..', 'input', 'test', '*.jpg')\n    files = sorted(glob(path))\n    X_test = []\n    X_test_id = []\n    total = 0\n    files_size = len(files)\n    for file in tqdm(files):\n        if total >= size or total >= files_size:\n            break\n        file_base = os.path.basename(file)\n        img = grayscale(file)\n        X_test.append(img)\n        X_test_id.append(file_base)\n        total += 1\n    return X_test, X_test_id\n\ndef normalize_valid_data(size):\n    test_data, test_ids = loadvalid(size)   \n    test_data = np.array(test_data, dtype=np.uint8)\n    test_data = test_data.reshape(-1,64,64,1)\n    return test_data, test_ids\n","metadata":{"execution":{"iopub.status.busy":"2021-12-07T00:36:15.198504Z","iopub.execute_input":"2021-12-07T00:36:15.199210Z","iopub.status.idle":"2021-12-07T00:36:21.152010Z","shell.execute_reply.started":"2021-12-07T00:36:15.199154Z","shell.execute_reply":"2021-12-07T00:36:21.150937Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"sample = 200\n\nx_train, x_test, y_train, y_test = normalize_train_data()\n\n# loading validation images\ntest_files, test_targets = normalize_valid_data(sample)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T00:36:21.153348Z","iopub.execute_input":"2021-12-07T00:36:21.154470Z","iopub.status.idle":"2021-12-07T00:39:50.114440Z","shell.execute_reply.started":"2021-12-07T00:36:21.154435Z","shell.execute_reply":"2021-12-07T00:39:50.113731Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\n\npx.histogram(df, x=\"classname\", color=\"classname\", title=\"Number of images by categories \")","metadata":{"execution":{"iopub.status.busy":"2021-12-07T00:39:50.117207Z","iopub.execute_input":"2021-12-07T00:39:50.117678Z","iopub.status.idle":"2021-12-07T00:39:53.417030Z","shell.execute_reply.started":"2021-12-07T00:39:50.117639Z","shell.execute_reply":"2021-12-07T00:39:53.416370Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nplt.figure(figsize = (12, 20))\nimage_count = 1\nBASE_URL = '../input/state-farm-distracted-driver-detection/imgs/train/'\nfor directory in os.listdir(BASE_URL):\n    if directory[0] != '.':\n        for i, file in enumerate(os.listdir(BASE_URL + directory)):\n            if i == 1:\n                break\n            else:\n                fig = plt.subplot(5, 2, image_count)\n                image_count += 1\n                image = mpimg.imread(BASE_URL + directory + '/' + file)\n                plt.imshow(image)\n                plt.title(types[directory])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T00:39:53.418070Z","iopub.execute_input":"2021-12-07T00:39:53.419309Z","iopub.status.idle":"2021-12-07T00:39:55.391997Z","shell.execute_reply.started":"2021-12-07T00:39:53.419268Z","shell.execute_reply":"2021-12-07T00:39:55.390646Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"CNN MODEL","metadata":{}},{"cell_type":"code","source":"#https://www.kaggle.com/ismailchaida/cnn-to-detect-driver-actions\n\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nbatch_size = 50\nnb_epoch = 5\nmodels_dir = \"saved_models\"\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)\n    \ncheckpointer = ModelCheckpoint(filepath='saved_models/weights_best.hdf5', \n                               monitor='val_loss', mode='min',\n                               verbose=1, save_best_only=True)\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T00:39:55.393110Z","iopub.execute_input":"2021-12-07T00:39:55.393498Z","iopub.status.idle":"2021-12-07T00:39:55.401017Z","shell.execute_reply.started":"2021-12-07T00:39:55.393465Z","shell.execute_reply":"2021-12-07T00:39:55.400109Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n\ndef cnn():\n    cnnmodel = Sequential()\n\n    cnnmodel.add(Conv2D(64,(3,3),activation='relu',input_shape=(64, 64, 1)))\n    cnnmodel.add(BatchNormalization())\n\n    cnnmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    cnnmodel.add(Dropout(0.3))\n    \n    cnnmodel.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n    cnnmodel.add(BatchNormalization())\n\n    cnnmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    cnnmodel.add(Dropout(0.3))\n    \n    cnnmodel.add(Conv2D(256,(3,3),activation='relu',padding='same'))\n    cnnmodel.add(BatchNormalization())\n\n    cnnmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    cnnmodel.add(Dropout(0.5))\n\n    cnnmodel.add(Flatten())\n    cnnmodel.add(Dense(512,activation='relu'))\n    cnnmodel.add(BatchNormalization())\n    cnnmodel.add(Dropout(0.5))\n    cnnmodel.add(Dense(128,activation='relu'))\n    cnnmodel.add(Dropout(0.25))\n    cnnmodel.add(Dense(10,activation='softmax'))\n    \n    return cnnmodel","metadata":{"execution":{"iopub.status.busy":"2021-12-07T00:39:55.402750Z","iopub.execute_input":"2021-12-07T00:39:55.403061Z","iopub.status.idle":"2021-12-07T00:39:55.417665Z","shell.execute_reply.started":"2021-12-07T00:39:55.403031Z","shell.execute_reply":"2021-12-07T00:39:55.416905Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\ncnnmodel = cnn()\n\ncnnmodel.summary()\nopt = keras.optimizers.Adam()\ncnnmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T00:39:55.419623Z","iopub.execute_input":"2021-12-07T00:39:55.420128Z","iopub.status.idle":"2021-12-07T00:39:58.416710Z","shell.execute_reply.started":"2021-12-07T00:39:55.420094Z","shell.execute_reply":"2021-12-07T00:39:58.416013Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import timeit\nhistory = cnnmodel.fit(x_train, y_train, \n          validation_data=(x_test, y_test),\n          epochs=nb_epoch, batch_size=batch_size, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T00:39:58.418039Z","iopub.execute_input":"2021-12-07T00:39:58.418305Z","iopub.status.idle":"2021-12-07T00:40:40.441895Z","shell.execute_reply.started":"2021-12-07T00:39:58.418272Z","shell.execute_reply":"2021-12-07T00:40:40.441089Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"score = cnnmodel.evaluate(x_test, y_test, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T00:40:40.443581Z","iopub.execute_input":"2021-12-07T00:40:40.443850Z","iopub.status.idle":"2021-12-07T00:40:41.199135Z","shell.execute_reply.started":"2021-12-07T00:40:40.443813Z","shell.execute_reply":"2021-12-07T00:40:41.198479Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#refrences\n\n#https://www.kaggle.com/ismailchaida/cnn-to-detect-driver-actions\n#https://www.kaggle.com/pierrelouisdanieau/computer-vision-tips-to-increase-accuracy\n#https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5\n#https://www.analyticsvidhya.com/blog/2021/06/building-a-convolutional-neural-network-using-tensorflow-keras/","metadata":{"execution":{"iopub.status.busy":"2021-12-07T00:40:41.200445Z","iopub.execute_input":"2021-12-07T00:40:41.200763Z","iopub.status.idle":"2021-12-07T00:40:41.205328Z","shell.execute_reply.started":"2021-12-07T00:40:41.200727Z","shell.execute_reply":"2021-12-07T00:40:41.204470Z"},"trusted":true},"execution_count":17,"outputs":[]}]}